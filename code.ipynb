{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## installing mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pulling the exisiting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import Video\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_face_mesh = mp.solutions.face_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face landmarks\n",
    "    if results.face_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, results.face_landmarks,\n",
    "            connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,\n",
    "            landmark_drawing_spec=mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "            connection_drawing_spec=mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "        )\n",
    "    # Draw pose landmarks\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, results.pose_landmarks,\n",
    "            connections=mp.solutions.pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "            connection_drawing_spec=mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "        )\n",
    "    # Draw left hand landmarks\n",
    "    if results.left_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, results.left_hand_landmarks,\n",
    "            connections=mp.solutions.hands.HAND_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing.DrawingSpec(color=(121,22,76), thickness=1, circle_radius=1),\n",
    "            connection_drawing_spec=mp_drawing.DrawingSpec(color=(121,44,250), thickness=1, circle_radius=1)\n",
    "        )\n",
    "    # Draw right hand landmarks\n",
    "    if results.right_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, results.right_hand_landmarks,\n",
    "            connections=mp.solutions.hands.HAND_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing.DrawingSpec(color=(245,117,66), thickness=1, circle_radius=1),\n",
    "            connection_drawing_spec=mp_drawing.DrawingSpec(color=(245,66,230), thickness=1, circle_radius=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading and projecting points on it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_display_video_inline(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Convert the frame to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = holistic.process(frame_rgb)\n",
    "\n",
    "            # Draw the styled landmarks on the frame\n",
    "            draw_styled_landmarks(frame, results)\n",
    "\n",
    "            # Convert the frame back to BGR for displaying with OpenCV in Jupyter\n",
    "            frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            # Convert the frame to a format IPython can display\n",
    "            im = Image.fromarray(frame_bgr)\n",
    "            \n",
    "            # Display the frame\n",
    "            display(im)\n",
    "            clear_output(wait=True)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
